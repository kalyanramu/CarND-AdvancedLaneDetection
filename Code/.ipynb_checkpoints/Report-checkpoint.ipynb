{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Lane Finding Project ###\n",
    "\n",
    "The main goal of the project is detect lanes on an image, find radius of curvature of the road and offset of center of car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps below is a processing pipeline to detect the lanes and make the measurements\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Overlay the lanes and measurements on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/se/D/CarND-Term1-Starter-Kit/CarND-AdvancedLaneDetection/CarND-AdvancedLaneDetection/Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Camera Calibration ###\n",
    "Why do we need to perform camera calibration?\n",
    "A good tutorial explaining these effects can be found at: http://aishack.in/tutorials/major-physical-defects-cameras/\n",
    "\n",
    "Cameras and lenses have distortion due to manufacturing. Theoritically a parabolic lens has the best performance, however it is hard to manufacture a parabolic lens. Most of the lens manufactured are spherical lens and this introduces two types of distortion: a) Radial Distoprtion b) Tangential Distortion\n",
    "\n",
    "* Radial distortion: \n",
    "Radial Distortion is caused due to the spherical shape of lens. This is because light travelling through center of lens doesn't get bent due to refraction. However, light passing through edges go through bending and thus the image at the periphery gets distorted. This type of distortion at the edges is described as \"Radial Distortion\"\n",
    "\n",
    "* Tangential Distortion:\n",
    "When the lens is not placed parallel to the imaging plane (the CCD sensor, etc) a tangential distortion is produced.\n",
    "\n",
    "\n",
    "\n",
    "The code for the unistorting is found in undistorter.py.\n",
    "\n",
    "** Algorithm:**\n",
    "\n",
    "* Find the corners in uncalibrated images (image points)\n",
    "* Create a list of object points i.e., where the points are in real-world(object points)\n",
    "* Use opencv calibrateCamera to get calibration matrix etc.,\n",
    "* Use the calibration matrix etc., to undistort a new image opencv's undistort function\n",
    "\n",
    "** Example Output **\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2: Thresholding to detect edges###\n",
    "\n",
    "Gradients are typically used to detect edges (or lines in this case). There are multiple gradient operators in computer vision, we will be using Sobel operator. Sobel operator highlights rapid changes in intensity. We will be using a simple sobel kernel and convolve with image to perform gradient operation.\n",
    "Also, to improve localizing the lanes we will be using our problem specific color thresholding. For color we simply convert the frame to HLS color space and apply a threshold on the S channel. The reason we use HLS here is because it proved to perform best in separating light pixels (road markings) from dark pixels (road) using the saturation channel.\n",
    "\n",
    "** Algorithm: **\n",
    "\n",
    "** Example Output **\n",
    "\n",
    "| Before Thresholding (road image)|After Thresholding|\n",
    "|---|---|\n",
    "| ![before cal](./report_images/distort_correct_img.png) | ![after cal](./report_images/thresholded_img.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Correct Perspective Error ###\n",
    "\n",
    "As we can see in the road image aove, the yellow lane and white lane appear to be converging while in reality we know that the lanes are parallel. This happens because of perpsective error. The perspective error on the images have to be corrected before we make measurement on the road curvature. We can notice in the images below that after the perspective correction, the lanes appear to be parallel as we expect.\n",
    "\n",
    "** Algorithm: **\n",
    "\n",
    "** Example Output: **\n",
    "\n",
    "| Before perspective correction (thresholded image)|After Perspective correction (thresholded image)|\n",
    "|---|---|\n",
    "| ![before cal](./report_images/thresholded_img.png) | ![after cal](./report_images/perspective_corrected.png) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Step 4: Detect Lanes using Sliding Window approach ###\n",
    "\n",
    "** Algorithm: **\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
